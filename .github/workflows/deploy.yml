name: Deploy to AWS
on:
  push:
    branches: [ "main" ]
  workflow_dispatch:

permissions:
  id-token: write
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  AWS_REGION: ap-south-1
  AWS_ACCOUNT_ID: "132418765186"
  ECR_REPOSITORY: "nicsan-crm-api"
  ECS_CLUSTER: "nicsan-backend-cluster"
  ECS_SERVICE: "nicsan-backend-svc"
  TASK_FAMILY: "nicsan-backend-task"
  CONTAINER_NAME: "backend"

  # --- New (safe defaults / optional) ---
  LOG_GROUP: "/ecs/nicsan-backend"
  LOG_RETENTION_DAYS: "30"

  # One-off migration (set these to enable)
  MIGRATION_SUBNETS: ""                 # e.g., "subnet-aaa,subnet-bbb"
  MIGRATION_SECURITY_GROUP: ""          # e.g., "sg-xxxxxxxx"
  MIGRATION_COMMAND_JSON: '["npx","prisma","migrate","deploy"]'  # change to your tool if needed

  # Optional autoscaling (set ENABLE_AUTOSCALING=true to enable)
  ENABLE_AUTOSCALING: "false"
  AS_MIN: "1"
  AS_MAX: "4"
  AS_CPU_TARGET: "50"                   # %
  AS_MEM_TARGET: "70"                   # %

  # Optional ALB alarm (set ENABLE_ALB_ALARM=true to enable)
  ENABLE_ALB_ALARM: "false"
  ALB_NAME: "nicsan-backend-alb"
  TG_NAME: "nicsan-backend-tg"
  SNS_TOPIC_ARN: ""                     # e.g., arn:aws:sns:ap-south-1:132418765186:nicsan-alb-health-alerts
  # --------------------------------------

jobs:
  deploy:
    runs-on: ubuntu-latest
    permissions:
      id-token: write
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Echo role arn
        run: echo "ROLE_TO_ASSUME=arn:aws:iam::132418765186:role/gha-ecs-deployer-nicsan-v2"

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::132418765186:role/gha-ecs-deployer-nicsan-v2
          aws-region: ${{ env.AWS_REGION }}
          audience: sts.amazonaws.com
          role-session-name: gha-${{ github.run_id }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Ensure backend Dockerfile exists at expected path
        shell: bash
        run: |
          set -e
          TARGET_DIR="nicsan-crm-backend"
          TARGET_FILE="$TARGET_DIR/Dockerfile"
          if [ -f "$TARGET_FILE" ]; then
            echo "✓ Found $TARGET_FILE"; exit 0
          fi
          echo "No Dockerfile at $TARGET_FILE. Searching repository..."
          FOUND=$(find . -maxdepth 3 -type f -name Dockerfile | head -n 1 || true)
          if [ -n "$FOUND" ]; then
            echo "Linking $FOUND -> $TARGET_FILE"
            mkdir -p "$TARGET_DIR"
            ln -s "$(realpath "$FOUND")" "$TARGET_FILE"
            ls -la "$TARGET_DIR"
            exit 0
          fi
          echo "❌ No Dockerfile found anywhere."; exit 1

      - name: Build, tag, and push image to ECR
        env:
          REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        run: |
          set -e
          BUILD_TAG="prod-$(date +%Y%m%d%H%M%S)"
          IMAGE_URI="$REGISTRY/${{ env.ECR_REPOSITORY }}:$BUILD_TAG"
          echo "IMAGE_URI=$IMAGE_URI" >> $GITHUB_ENV
          echo "Building:  $IMAGE_URI"
          docker build -f nicsan-crm-backend/Dockerfile -t "$IMAGE_URI" nicsan-crm-backend
          echo "Pushing:   $IMAGE_URI"
          docker push "$IMAGE_URI"

      - name: Download current task definition
        run: |
          aws ecs describe-task-definition \
            --task-definition "${{ env.TASK_FAMILY }}" \
            --query taskDefinition > task-def.json

      - name: Sanitize task definition for ECS register
        shell: bash
        run: |
          set -e
          # Keep only registerable fields; drop read-only/unsupported; remove all nulls.
          jq '{
            family: .family,
            taskRoleArn: .taskRoleArn,
            executionRoleArn: .executionRoleArn,
            networkMode: .networkMode,
            containerDefinitions: (
              .containerDefinitions
              | map(del(
                  .enableFaultInjection,
                  .repositoryCredentials,
                  .firelensConfiguration,
                  .systemControls,
                  .ulimits,
                  .credentialSpecs
                ))
            ),
            volumes: .volumes,
            placementConstraints: .placementConstraints,
            requiresCompatibilities: .requiresCompatibilities,
            cpu: .cpu,
            memory: .memory,
            pidMode: .pidMode,
            ipcMode: .ipcMode,
            proxyConfiguration: .proxyConfiguration,
            inferenceAccelerators: .inferenceAccelerators,
            ephemeralStorage: .ephemeralStorage,
            runtimePlatform: .runtimePlatform
          } | del(.. | nulls)' task-def.json > task-def.clean.json
          mv task-def.clean.json task-def.json
          echo "✅ task-def.json sanitized"

      - name: Render container image into task-def (jq)
        run: |
          set -e
          jq --arg img "${IMAGE_URI}" --arg name "${CONTAINER_NAME}" \
            '(.containerDefinitions[] | select(.name==$name) | .image) = $img' \
            task-def.json > task-def.rendered.json
          mv task-def.rendered.json task-def.json
          echo "🔧 Image set to ${IMAGE_URI}"

      - name: Register task definition (CLI)
        id: reg
        run: |
          set -e
          ARN=$(aws ecs register-task-definition \
            --cli-input-json file://task-def.json \
            --query 'taskDefinition.taskDefinitionArn' --output text)
          echo "TASKDEF_ARN=$ARN" >> $GITHUB_ENV
          echo "🆕 Registered: $ARN"

      # ---------- NEW: Optional one-off DB migrations ----------
      - name: Run DB migrations (one-off ECS task)
        if: ${{ env.MIGRATION_SUBNETS != '' && env.MIGRATION_SECURITY_GROUP != '' }}
        run: |
          set -e
          echo "Running DB migrations using ${TASKDEF_ARN}"
          CMD_JSON='${{ env.MIGRATION_COMMAND_JSON }}'
          TASK_ARN=$(aws ecs run-task \
            --cluster "${ECS_CLUSTER}" \
            --launch-type FARGATE \
            --task-definition "${TASKDEF_ARN}" \
            --network-configuration "awsvpcConfiguration={subnets=[${{ env.MIGRATION_SUBNETS }}],securityGroups=[${{ env.MIGRATION_SECURITY_GROUP }}],assignPublicIp=DISABLED}" \
            --overrides "$(jq -n --arg name "${CONTAINER_NAME}" --argjson cmd "${CMD_JSON}" '{containerOverrides:[{name:$name,command:$cmd}]}')" \
            --query 'tasks[0].taskArn' --output text)
          echo "Started migration task: $TASK_ARN"
          aws ecs wait tasks-stopped --cluster "${ECS_CLUSTER}" --tasks "$TASK_ARN"
          EXIT_CODE=$(aws ecs describe-tasks --cluster "${ECS_CLUSTER}" --tasks "$TASK_ARN" \
            --query 'tasks[0].containers[0].exitCode' --output text)
          if [ "$EXIT_CODE" != "0" ]; then
            echo "❌ Migration failed with exit code $EXIT_CODE"; exit 1
          fi
          echo "✅ Migration succeeded"
      - name: Skip migrations (missing env)
        if: ${{ !(env.MIGRATION_SUBNETS != '' && env.MIGRATION_SECURITY_GROUP != '') }}
        run: echo "⏭️  Skipping migrations (set MIGRATION_SUBNETS and MIGRATION_SECURITY_GROUP to enable)."
      # ---------------------------------------------------------

      - name: Update service & wait for stability (CLI)
        run: |
          set -e
          aws ecs update-service \
            --cluster "${ECS_CLUSTER}" \
            --service "${ECS_SERVICE}" \
            --task-definition "${TASKDEF_ARN}" \
            --force-new-deployment >/dev/null
          aws ecs wait services-stable \
            --cluster "${ECS_CLUSTER}" \
            --services "${ECS_SERVICE}"
          echo "✅ Service stable"

      # ---------- NEW: Idempotent log retention ----------
      - name: Ensure CloudWatch log retention
        run: |
          aws logs put-retention-policy \
            --log-group-name "${LOG_GROUP}" \
            --retention-in-days "${LOG_RETENTION_DAYS}"
      # ---------------------------------------------------

      # ---------- NEW: Optional autoscaling ----------
      - name: Configure ECS autoscaling (idempotent)
        if: ${{ env.ENABLE_AUTOSCALING == 'true' }}
        run: |
          set -e
          aws application-autoscaling register-scalable-target \
            --service-namespace ecs \
            --resource-id service/${ECS_CLUSTER}/${ECS_SERVICE} \
            --scalable-dimension ecs:service:DesiredCount \
            --min-capacity ${AS_MIN} --max-capacity ${AS_MAX}
          aws application-autoscaling put-scaling-policy \
            --service-namespace ecs \
            --resource-id service/${ECS_CLUSTER}/${ECS_SERVICE} \
            --scalable-dimension ecs:service:DesiredCount \
            --policy-name cpu-target \
            --policy-type TargetTrackingScaling \
            --target-tracking-scaling-policy-configuration "{
              \"TargetValue\": ${AS_CPU_TARGET},
              \"PredefinedMetricSpecification\": {\"PredefinedMetricType\":\"ECSServiceAverageCPUUtilization\"},
              \"ScaleInCooldown\": 60, \"ScaleOutCooldown\": 60
            }"
          aws application-autoscaling put-scaling-policy \
            --service-namespace ecs \
            --resource-id service/${ECS_CLUSTER}/${ECS_SERVICE} \
            --scalable-dimension ecs:service:DesiredCount \
            --policy-name mem-target \
            --policy-type TargetTrackingScaling \
            --target-tracking-scaling-policy-configuration "{
              \"TargetValue\": ${AS_MEM_TARGET},
              \"PredefinedMetricSpecification\": {\"PredefinedMetricType\":\"ECSServiceAverageMemoryUtilization\"},
              \"ScaleInCooldown\": 60, \"ScaleOutCooldown\": 60
            }"
      # ---------------------------------------------------

      # ---------- NEW: Optional ALB UnHealthyHostCount alarm ----------
      - name: Ensure ALB health alarm (5m >0)
        if: ${{ env.ENABLE_ALB_ALARM == 'true' && env.SNS_TOPIC_ARN != '' }}
        run: |
          set -e
          TG_ARN=$(aws elbv2 describe-target-groups --names "${TG_NAME}" --query 'TargetGroups[0].TargetGroupArn' --output text)
          ALB_ARN=$(aws elbv2 describe-load-balancers --names "${ALB_NAME}" --query 'LoadBalancers[0].LoadBalancerArn' --output text)
          TG_DIM=${TG_ARN#arn:aws:elasticloadbalancing:${AWS_REGION}:*:targetgroup/}
          ALB_DIM=${ALB_ARN#arn:aws:elasticloadbalancing:${AWS_REGION}:*:loadbalancer/}
          aws cloudwatch put-metric-alarm \
            --alarm-name "ALB-UnHealthyHostCount>0-5m" \
            --metric-name UnHealthyHostCount \
            --namespace AWS/ApplicationELB \
            --statistic Maximum \
            --period 60 \
            --evaluation-periods 5 \
            --threshold 0 \
            --comparison-operator GreaterThanThreshold \
            --dimensions Name=TargetGroup,Value="$TG_DIM" Name=LoadBalancer,Value="$ALB_DIM" \
            --treat-missing-data notBreaching \
            --alarm-actions "${SNS_TOPIC_ARN}"
      # ---------------------------------------------------------------

      - name: Debug GitHub Context
        run: |
          echo "Repository: ${{ github.repository }}"
          echo "Ref: ${{ github.ref }}"
          echo "Expected: repo:NicsanIN/nicsan_crm-Deployed:ref:refs/heads/main"
          echo "Actual: repo:${{ github.repository }}:${{ github.ref }}"

      - name: DEBUG — show OIDC claims
        if: always()
        shell: bash
        run: |
          set +e
          TOK_JSON=$(curl -s -H "Authorization: bearer $ACTIONS_ID_TOKEN_REQUEST_TOKEN" \
            "$ACTIONS_ID_TOKEN_REQUEST_URL&audience=sts.amazonaws.com")
          TOK=$(echo "$TOK_JSON" | jq -r .value)
          echo "$TOK" | cut -d '.' -f2 | base64 -d 2>/dev/null | jq '{iss, aud, sub}' || true
